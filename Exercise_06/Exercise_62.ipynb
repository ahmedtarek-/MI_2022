{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bf05d93-b179-4433-bd36-5b3aefd93872",
   "metadata": {},
   "source": [
    "# MI\n",
    "**_Ahmed - Luisa - Myria_**\n",
    "\n",
    "## Exercise H62.1: Long short-term memory (LSTM)\n",
    "\n",
    "### a) Creating training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc4d3cf1-d98e-4f12-bc94-a16cad07f72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "SERIES_SIZE = 30\n",
    "\n",
    "def generate_series(series_size, total_count):\n",
    "    # res = []\n",
    "    # for i in range(total_count):\n",
    "    #     res.append([list(np.random.randint(0,10, 1)) for k in range(series_size)])\n",
    "    return [list(np.random.randint(0, 10, series_size)) for i in range(total_count)]\n",
    "\n",
    "def evaluate_series(series):\n",
    "    # return 1 if sum([s[0] for s in series]) >= 100 else 0\n",
    "    return 1 if sum(series) >= 100 else 0\n",
    "\n",
    "def generate_input_output(collection_of_series):\n",
    "    output = [evaluate_series(series) for series in collection_of_series]\n",
    "    return np.array(collection_of_series), output\n",
    "\n",
    "X_train, y_train = generate_input_output(generate_series(SERIES_SIZE, 8000))\n",
    "X_holdout, y_holdout = generate_input_output(generate_series(SERIES_SIZE, 2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5d7a22-4420-41f4-b079-b048a3fdbf2a",
   "metadata": {},
   "source": [
    "### b) Building an RNN\n",
    "\n",
    "**1. Prepare the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99944f1b-8966-4ad2-9f13-77a4f44185a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reshape to 3D (samples_size, sequence_length, features)\n",
    "X_train = X_train.reshape(len(X_train), SERIES_SIZE, 1)\n",
    "X_holdout = X_holdout.reshape(len(X_holdout), SERIES_SIZE, 1)\n",
    "\n",
    "# Make sure all are as array to avoid model complaining\n",
    "X_train = np.asarray(X_train)\n",
    "X_holdout = np.asarray(X_holdout)\n",
    "\n",
    "y_train = np.asarray(y_train)\n",
    "y_holdout = np.asarray(y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda606cc-bc26-4759-b82d-0f7ab0994043",
   "metadata": {},
   "source": [
    "**2. Define the LSTM model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f18cd2f-fb67-4f52-90c0-8d9c5edca480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 200)               161600    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 201       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,801\n",
      "Trainable params: 161,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Input, optimizers\n",
    "from tensorflow.keras.layers import Dense, Activation, LSTM, Embedding\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(200, activation='relu', input_shape=(30, 1)))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.add(Activation('sigmoid'))\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c307d79-26fc-4fbd-b0e6-c91d2915aa62",
   "metadata": {},
   "source": [
    "**3. Compile and run the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fca5f8b3-5d67-4ed4-b3ec-2ce3cc3b9c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "160/160 [==============================] - 6s 32ms/step - loss: 0.0529 - accuracy: 0.9865 - val_loss: 0.0515 - val_accuracy: 0.9815\n",
      "Epoch 2/60\n",
      "160/160 [==============================] - 5s 31ms/step - loss: 0.0414 - accuracy: 0.9865 - val_loss: 0.0579 - val_accuracy: 0.9815\n",
      "Epoch 3/60\n",
      "160/160 [==============================] - 5s 33ms/step - loss: 0.0493 - accuracy: 0.9865 - val_loss: 0.3252 - val_accuracy: 0.9815\n",
      "Epoch 4/60\n",
      "160/160 [==============================] - 6s 35ms/step - loss: 0.0602 - accuracy: 0.9862 - val_loss: 0.1842 - val_accuracy: 0.9815\n",
      "Epoch 5/60\n",
      "160/160 [==============================] - 5s 34ms/step - loss: 0.0433 - accuracy: 0.9865 - val_loss: 0.0418 - val_accuracy: 0.9815\n",
      "Epoch 6/60\n",
      "160/160 [==============================] - 6s 36ms/step - loss: 0.0287 - accuracy: 0.9865 - val_loss: 0.0453 - val_accuracy: 0.9815\n",
      "Epoch 7/60\n",
      "160/160 [==============================] - 6s 35ms/step - loss: 0.0326 - accuracy: 0.9865 - val_loss: 0.0395 - val_accuracy: 0.9815\n",
      "Epoch 8/60\n",
      "160/160 [==============================] - 5s 31ms/step - loss: 0.0330 - accuracy: 0.9865 - val_loss: 0.0390 - val_accuracy: 0.9815\n",
      "Epoch 9/60\n",
      "160/160 [==============================] - 5s 32ms/step - loss: 0.0270 - accuracy: 0.9865 - val_loss: 0.0424 - val_accuracy: 0.9815\n",
      "Epoch 10/60\n",
      "160/160 [==============================] - 6s 38ms/step - loss: 0.0271 - accuracy: 0.9865 - val_loss: 0.0384 - val_accuracy: 0.9815\n",
      "Epoch 11/60\n",
      "160/160 [==============================] - 5s 31ms/step - loss: 0.0265 - accuracy: 0.9865 - val_loss: 0.0362 - val_accuracy: 0.9815\n",
      "Epoch 12/60\n",
      "160/160 [==============================] - 5s 32ms/step - loss: 0.0293 - accuracy: 0.9865 - val_loss: 0.0402 - val_accuracy: 0.9830\n",
      "Epoch 13/60\n",
      "160/160 [==============================] - 6s 35ms/step - loss: 0.0384 - accuracy: 0.9864 - val_loss: 0.0439 - val_accuracy: 0.9815\n",
      "Epoch 14/60\n",
      "160/160 [==============================] - 5s 33ms/step - loss: 0.0255 - accuracy: 0.9865 - val_loss: 0.0320 - val_accuracy: 0.9815\n",
      "Epoch 15/60\n",
      "160/160 [==============================] - 5s 33ms/step - loss: 0.0947 - accuracy: 0.9856 - val_loss: 0.0574 - val_accuracy: 0.9815\n",
      "Epoch 16/60\n",
      "160/160 [==============================] - 6s 37ms/step - loss: 0.0320 - accuracy: 0.9865 - val_loss: 0.0380 - val_accuracy: 0.9815\n",
      "Epoch 17/60\n",
      "160/160 [==============================] - 5s 33ms/step - loss: 0.0337 - accuracy: 0.9865 - val_loss: 0.0360 - val_accuracy: 0.9815\n",
      "Epoch 18/60\n",
      "160/160 [==============================] - 5s 30ms/step - loss: 0.0520 - accuracy: 0.9864 - val_loss: 0.1343 - val_accuracy: 0.9815\n",
      "Epoch 19/60\n",
      "160/160 [==============================] - 6s 37ms/step - loss: 0.1937 - accuracy: 0.9864 - val_loss: 0.0831 - val_accuracy: 0.9815\n",
      "Epoch 20/60\n",
      "160/160 [==============================] - 5s 31ms/step - loss: 0.0332 - accuracy: 0.9865 - val_loss: 0.0363 - val_accuracy: 0.9815\n",
      "Epoch 21/60\n",
      "160/160 [==============================] - 5s 32ms/step - loss: 0.0268 - accuracy: 0.9870 - val_loss: 0.0337 - val_accuracy: 0.9815\n",
      "Epoch 22/60\n",
      "160/160 [==============================] - 6s 39ms/step - loss: 0.0205 - accuracy: 0.9905 - val_loss: 0.0287 - val_accuracy: 0.9895\n",
      "Epoch 23/60\n",
      "160/160 [==============================] - 6s 35ms/step - loss: 0.0186 - accuracy: 0.9924 - val_loss: 0.0222 - val_accuracy: 0.9920\n",
      "Epoch 24/60\n",
      "160/160 [==============================] - 6s 40ms/step - loss: 0.0151 - accuracy: 0.9945 - val_loss: 0.0233 - val_accuracy: 0.9920\n",
      "Epoch 25/60\n",
      "160/160 [==============================] - 6s 38ms/step - loss: 0.0133 - accuracy: 0.9945 - val_loss: 0.0177 - val_accuracy: 0.9950\n",
      "Epoch 26/60\n",
      "160/160 [==============================] - 6s 36ms/step - loss: 0.0124 - accuracy: 0.9940 - val_loss: 0.0181 - val_accuracy: 0.9955\n",
      "Epoch 27/60\n",
      "160/160 [==============================] - 6s 38ms/step - loss: 0.0132 - accuracy: 0.9944 - val_loss: 0.0159 - val_accuracy: 0.9945\n",
      "Epoch 28/60\n",
      "160/160 [==============================] - 6s 35ms/step - loss: 0.0118 - accuracy: 0.9951 - val_loss: 0.0202 - val_accuracy: 0.9925\n",
      "Epoch 29/60\n",
      "160/160 [==============================] - 6s 36ms/step - loss: 0.0117 - accuracy: 0.9951 - val_loss: 0.0127 - val_accuracy: 0.9945\n",
      "Epoch 30/60\n",
      "160/160 [==============================] - 6s 38ms/step - loss: 213.8759 - accuracy: 0.9899 - val_loss: 0.0507 - val_accuracy: 0.9815\n",
      "Epoch 31/60\n",
      "160/160 [==============================] - 5s 30ms/step - loss: 0.0337 - accuracy: 0.9865 - val_loss: 0.0442 - val_accuracy: 0.9815\n",
      "Epoch 32/60\n",
      "160/160 [==============================] - 8s 50ms/step - loss: 0.0308 - accuracy: 0.9865 - val_loss: 0.0789 - val_accuracy: 0.9815\n",
      "Epoch 33/60\n",
      "160/160 [==============================] - 7s 43ms/step - loss: 0.1171 - accuracy: 0.9865 - val_loss: 0.0600 - val_accuracy: 0.9815\n",
      "Epoch 34/60\n",
      "160/160 [==============================] - 5s 34ms/step - loss: 0.0348 - accuracy: 0.9865 - val_loss: 0.0421 - val_accuracy: 0.9815\n",
      "Epoch 35/60\n",
      "160/160 [==============================] - 6s 36ms/step - loss: 0.0316 - accuracy: 0.9865 - val_loss: 0.0475 - val_accuracy: 0.9815\n",
      "Epoch 36/60\n",
      "160/160 [==============================] - 5s 31ms/step - loss: 0.0286 - accuracy: 0.9865 - val_loss: 0.0401 - val_accuracy: 0.9815\n",
      "Epoch 37/60\n",
      "160/160 [==============================] - 5s 33ms/step - loss: 0.0353 - accuracy: 0.9864 - val_loss: 0.0406 - val_accuracy: 0.9815\n",
      "Epoch 38/60\n",
      "160/160 [==============================] - 5s 33ms/step - loss: 0.0289 - accuracy: 0.9865 - val_loss: 0.0398 - val_accuracy: 0.9815\n",
      "Epoch 39/60\n",
      "160/160 [==============================] - 5s 32ms/step - loss: 0.0270 - accuracy: 0.9865 - val_loss: 0.0362 - val_accuracy: 0.9815\n",
      "Epoch 40/60\n",
      "160/160 [==============================] - 6s 38ms/step - loss: 0.2970 - accuracy: 0.9776 - val_loss: 0.0408 - val_accuracy: 0.9815\n",
      "Epoch 41/60\n",
      "160/160 [==============================] - 5s 34ms/step - loss: 0.0303 - accuracy: 0.9865 - val_loss: 0.0430 - val_accuracy: 0.9815\n",
      "Epoch 42/60\n",
      "160/160 [==============================] - 5s 33ms/step - loss: 0.0280 - accuracy: 0.9865 - val_loss: 0.0362 - val_accuracy: 0.9815\n",
      "Epoch 43/60\n",
      "160/160 [==============================] - 5s 32ms/step - loss: 0.0280 - accuracy: 0.9865 - val_loss: 0.0332 - val_accuracy: 0.9815\n",
      "Epoch 44/60\n",
      "160/160 [==============================] - 5s 34ms/step - loss: 0.0253 - accuracy: 0.9866 - val_loss: 0.0320 - val_accuracy: 0.9815\n",
      "Epoch 45/60\n",
      "160/160 [==============================] - 6s 37ms/step - loss: 0.0252 - accuracy: 0.9866 - val_loss: 0.0327 - val_accuracy: 0.9815\n",
      "Epoch 46/60\n",
      "160/160 [==============================] - 5s 33ms/step - loss: 0.0220 - accuracy: 0.9872 - val_loss: 0.0254 - val_accuracy: 0.9890\n",
      "Epoch 47/60\n",
      "160/160 [==============================] - 5s 31ms/step - loss: 0.0201 - accuracy: 0.9909 - val_loss: 0.0232 - val_accuracy: 0.9870\n",
      "Epoch 48/60\n",
      "160/160 [==============================] - 5s 31ms/step - loss: 0.0160 - accuracy: 0.9926 - val_loss: 0.0263 - val_accuracy: 0.9870\n",
      "Epoch 49/60\n",
      "160/160 [==============================] - 5s 33ms/step - loss: 0.0138 - accuracy: 0.9946 - val_loss: 0.0118 - val_accuracy: 0.9980\n",
      "Epoch 50/60\n",
      "160/160 [==============================] - 5s 31ms/step - loss: 0.0203 - accuracy: 0.9919 - val_loss: 0.0225 - val_accuracy: 0.9880\n",
      "Epoch 51/60\n",
      "160/160 [==============================] - 7s 44ms/step - loss: 0.0137 - accuracy: 0.9941 - val_loss: 0.0156 - val_accuracy: 0.9960\n",
      "Epoch 52/60\n",
      "160/160 [==============================] - 5s 34ms/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.0102 - val_accuracy: 0.9985\n",
      "Epoch 53/60\n",
      "160/160 [==============================] - 5s 34ms/step - loss: 0.0116 - accuracy: 0.9954 - val_loss: 0.0093 - val_accuracy: 0.9985\n",
      "Epoch 54/60\n",
      "160/160 [==============================] - 5s 30ms/step - loss: 0.0146 - accuracy: 0.9937 - val_loss: 0.0287 - val_accuracy: 0.9860\n",
      "Epoch 55/60\n",
      "160/160 [==============================] - 5s 31ms/step - loss: 0.0127 - accuracy: 0.9941 - val_loss: 0.0272 - val_accuracy: 0.9880\n",
      "Epoch 56/60\n",
      "160/160 [==============================] - 5s 34ms/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 0.0097 - val_accuracy: 0.9965\n",
      "Epoch 57/60\n",
      "160/160 [==============================] - 6s 35ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.0106 - val_accuracy: 0.9985\n",
      "Epoch 58/60\n",
      "160/160 [==============================] - 5s 31ms/step - loss: 0.0135 - accuracy: 0.9942 - val_loss: 0.0205 - val_accuracy: 0.9950\n",
      "Epoch 59/60\n",
      "160/160 [==============================] - 5s 32ms/step - loss: 0.0115 - accuracy: 0.9945 - val_loss: 0.0094 - val_accuracy: 0.9990\n",
      "Epoch 60/60\n",
      "160/160 [==============================] - 5s 31ms/step - loss: 0.0107 - accuracy: 0.9956 - val_loss: 0.0176 - val_accuracy: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd59b1ee80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.backend import clear_session\n",
    "clear_session()\n",
    "\n",
    "lstm_model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=optimizers.Adam(\n",
    "                  learning_rate=0.001,\n",
    "                  beta_1=0.9,\n",
    "                  beta_2=0.999,\n",
    "                  epsilon=1e-08\n",
    "              ),\n",
    "    metrics=[\"accuracy\"])\n",
    "lstm_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=50,\n",
    "    epochs=60,\n",
    "    validation_data=(X_holdout, y_holdout)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a31ae80-846c-4b26-8860-4799f268bc8e",
   "metadata": {},
   "source": [
    "**4. Test the model using a novel prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64a76e1e-d48b-4464-b088-c153dea6aad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1/1 [==============================] - 0s 159ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randint(0, 10, SERIES_SIZE)\n",
    "y = 1 if np.sum(x) > 100 >= 100 else 0 \n",
    "\n",
    "x = np.asarray(x.reshape(1, SERIES_SIZE, 1))\n",
    "print(y)\n",
    "\n",
    "lstm_model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3985456e-be79-4f2c-9c07-7b0c50e8fb06",
   "metadata": {},
   "source": [
    "**5. Class distribuition of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "361147d2-ec70-4ee9-8964-f41103e03a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We can see that most of the data has a value 1 (i.e sum of sequence is > 100). This is not optimal for learning\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts, bins = np.histogram(y_train, bins=[0,1,2])\n",
    "# plt.stairs(counts, bins)\n",
    "# counts\n",
    "plt.subplot(211)\n",
    "plt.hist(y_train, bins=[0,1,2])\n",
    "plt.subplot(212)\n",
    "plt.hist(y_holdout, bins=[0,1,2])\n",
    "plt.show()\n",
    "\n",
    "print(\"\"\"\n",
    "We can see that most of the data has a value 1 (i.e sum of sequence is > 100). This is not optimal for learning\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1484ef-d91f-4a93-883c-9516ea4e93da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
